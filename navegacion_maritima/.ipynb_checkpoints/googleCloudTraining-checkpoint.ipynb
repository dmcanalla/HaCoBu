{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c8802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celda 1: Librerías importadas y listas para Google Cloud.\n"
     ]
    }
   ],
   "source": [
    "# CELDA 1: Imports (Modificada para Google Cloud)\n",
    "# Todo lo necesario\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os # Aunque su uso disminuirá para rutas de archivos\n",
    "import pickle # Lo mantenemos por si quieres usarlo para objetos simples\n",
    "import joblib # Recomendado para guardar modelos y objetos grandes de scikit-learn\n",
    "\n",
    "# Para interactuar con Google Cloud Storage\n",
    "from google.cloud import storage\n",
    "import fsspec\n",
    "import gcsfs # Permite a pandas y otras libs usar \"gs://\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Opcional: Instalar gcsfs y joblib si no están presentes en el entorno de Vertex AI\n",
    "# (generalmente sí lo están). Descomenta la siguiente línea si es necesario.\n",
    "# !pip install gcsfs joblib --quiet --user\n",
    "\n",
    "print(\"Celda 1: Librerías importadas y listas para Google Cloud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a11464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intentando listar archivos CSV desde: gs://TU_BUCKET_GCS/RUTA_A_TUS_CSV/\n",
      "Ocurrió un error al acceder al bucket de GCS o listar archivos: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.\n",
      "Asegúrate de que el nombre del bucket y el prefijo son correctos y que tienes permisos.\n",
      "\n",
      "No se encontraron archivos CSV en la ruta especificada, o hubo un error previo.\n",
      "El DataFrame df_datos está vacío.\n",
      "\n",
      "Celda 2: Carga de datos desde GCS completada (o intentada).\n"
     ]
    }
   ],
   "source": [
    "# CELDA 2: Carga de Datos de Entrenamiento (Modificada para GCS)\n",
    "\n",
    "# ------------- POR FAVOR, CONFIGURA ESTAS VARIABLES -------------\n",
    "bucket_name = \"TU_BUCKET_GCS\"  # Reemplaza con el nombre de tu bucket\n",
    "prefix_path_csv = \"RUTA_A_TUS_CSV/\" # Reemplaza con la ruta a tus CSVs dentro del bucket\n",
    "# Ejemplo: bucket_name = \"mi-bucket-maritimo\"\n",
    "# Ejemplo: prefix_path_csv = \"datos_etiquetados_csv/\"\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "lista_df = []\n",
    "df_datos = pd.DataFrame() # Inicializar por si no se cargan archivos\n",
    "\n",
    "print(f\"Intentando listar archivos CSV desde: gs://{bucket_name}/{prefix_path_csv}\")\n",
    "\n",
    "# Inicializar cliente de GCS\n",
    "try:\n",
    "    storage_client = storage.Client() # No necesitas pasar el proyecto si el entorno está bien configurado (ej. en Vertex AI)\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix=prefix_path_csv)\n",
    "    \n",
    "    archivos_csv_encontrados = []\n",
    "    for blob in blobs:\n",
    "        if blob.name.lower().endswith('.csv') and not blob.name.endswith('/'): # Evitar \"carpetas\" vacías\n",
    "            archivos_csv_encontrados.append(blob.name)\n",
    "    \n",
    "    if not archivos_csv_encontrados:\n",
    "        print(f\"Advertencia: No se encontraron archivos CSV en 'gs://{bucket_name}/{prefix_path_csv}'\")\n",
    "    else:\n",
    "        print(f\"Archivos CSV encontrados en 'gs://{bucket_name}/{prefix_path_csv}': {len(archivos_csv_encontrados)} items.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al acceder al bucket de GCS o listar archivos: {e}\")\n",
    "    print(\"Asegúrate de que el nombre del bucket y el prefijo son correctos y que tienes permisos.\")\n",
    "    archivos_csv_encontrados = []\n",
    "\n",
    "contador_cargados = 0\n",
    "if archivos_csv_encontrados:\n",
    "    print(f\"\\nIniciando carga de {len(archivos_csv_encontrados)} archivos CSV...\")\n",
    "    for i, blob_name in enumerate(archivos_csv_encontrados):\n",
    "        gs_path = f\"gs://{bucket_name}/{blob_name}\"\n",
    "        try:\n",
    "            df_temporal = pd.read_csv(gs_path)\n",
    "            lista_df.append(df_temporal)\n",
    "            contador_cargados += 1\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(archivos_csv_encontrados): # Imprimir progreso\n",
    "                 print(f\"Cargados {contador_cargados}/{len(archivos_csv_encontrados)} archivos... (Último: {blob_name})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar el archivo '{blob_name}' desde GCS: {e}\")\n",
    "            \n",
    "if lista_df:\n",
    "    df_datos = pd.concat(lista_df, ignore_index=True)\n",
    "    print(f\"\\nSe combinaron {contador_cargados} archivos CSV de entrenamiento desde GCS.\")\n",
    "    print(f\"df_datos (entrenamiento) cargado con {df_datos.shape[0]} filas y {df_datos.shape[1]} columnas.\")\n",
    "else:\n",
    "    if archivos_csv_encontrados:\n",
    "        print(f\"\\nNo se pudo cargar ningún archivo CSV de la ruta 'gs://{bucket_name}/{prefix_path_csv}' a pesar de encontrarlos.\")\n",
    "    else:\n",
    "        print(f\"\\nNo se encontraron archivos CSV en la ruta especificada, o hubo un error previo.\")\n",
    "    print(\"El DataFrame df_datos está vacío.\")\n",
    "\n",
    "print(\"\\nCelda 2: Carga de datos desde GCS completada (o intentada).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dbf140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El DataFrame df_datos (entrenamiento) está vacío. No se pueden mostrar las primeras filas.\n",
      "\n",
      "Celda 3: Visualización opcional completada.\n"
     ]
    }
   ],
   "source": [
    "# CELDA 3: Visualización Opcional (Entrenamiento)\n",
    "if not df_datos.empty:\n",
    "    print(\"\\nPrimeras filas de df_datos (entrenamiento original cargado desde GCS):\")\n",
    "    display(df_datos.head())\n",
    "else:\n",
    "    print(\"\\nEl DataFrame df_datos (entrenamiento) está vacío. No se pueden mostrar las primeras filas.\")\n",
    "\n",
    "print(\"\\nCelda 3: Visualización opcional completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1989e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame df_datos (entrenamiento) está vacío. Saltando preprocesamiento.\n",
      "\n",
      "Celda 4: Preprocesamiento y guardado de artefactos en GCS completado (o intentado).\n"
     ]
    }
   ],
   "source": [
    "# CELDA 4: Preprocesamiento de Datos de Entrenamiento y Definición de X, y (Modificada para GCS)\n",
    "\n",
    "# ------------- POR FAVOR, CONFIGURA ESTAS VARIABLES (si no lo hiciste en Celda 2) -------------\n",
    "# bucket_name = \"TU_BUCKET_GCS\" # Ya debería estar definido en Celda 2\n",
    "prefix_path_artefactos = \"RUTA_PARA_ARTEFACTOS/\" # Reemplaza con la ruta para guardar artefactos\n",
    "# Ejemplo: prefix_path_artefactos = \"artefactos_entrenamiento/\"\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "# Variables globales que se guardarán para usar en la predicción\n",
    "columnas_categoricas_originales_para_dummies = []\n",
    "columnas_X_finales = []\n",
    "dificultad_map = {'BAJA': 0, 'MEDIA': 1, 'ALTA': 2} # Definición global\n",
    "\n",
    "X_features = np.array([[]]) # Inicializar para evitar NameError\n",
    "y_objetivo_modelo1 = np.array([]) # Inicializar\n",
    "\n",
    "if df_datos.empty:\n",
    "    print(\"El DataFrame df_datos (entrenamiento) está vacío. Saltando preprocesamiento.\")\n",
    "else:\n",
    "    print(\"\\n--- Iniciando Preprocesamiento de Datos de Entrenamiento ---\")\n",
    "    df_procesado = df_datos.copy()\n",
    "\n",
    "    col_dificultad_situacion = 'DificultadSituacion'\n",
    "    col_dificultad_ejercicio = 'DificultadEjercicio'\n",
    "\n",
    "    for col_target in [col_dificultad_situacion, col_dificultad_ejercicio]:\n",
    "        if col_target in df_procesado.columns:\n",
    "            df_procesado[col_target] = df_procesado[col_target].map(dificultad_map)\n",
    "    print(f\"Columnas de dificultad mapeadas a números.\")\n",
    "\n",
    "    columnas_ids_y_etiquetas = ['Ejercicio', 'Situacion_n', col_dificultad_situacion, col_dificultad_ejercicio]\n",
    "    columnas_features_potenciales = [col for col in df_procesado.columns if col not in columnas_ids_y_etiquetas]\n",
    "    \n",
    "    columnas_categoricas_originales_para_dummies = [\n",
    "        col for col in columnas_features_potenciales if df_procesado[col].dtype == 'object'\n",
    "    ]\n",
    "    print(f\"Columnas categóricas originales (entrenamiento) para dummies: {columnas_categoricas_originales_para_dummies}\")\n",
    "\n",
    "    for col_cat in columnas_categoricas_originales_para_dummies:\n",
    "        df_procesado[col_cat] = df_procesado[col_cat].replace('N/C', 'NC_Valor') # Reemplazar 'N/C'\n",
    "        moda_col = df_procesado[col_cat].mode()\n",
    "        # Asegurarse que la moda no esté vacía y usar 'Desconocido' como último recurso\n",
    "        df_procesado[col_cat] = df_procesado[col_cat].fillna(moda_col[0] if not moda_col.empty else 'Desconocido')\n",
    "    \n",
    "    df_listo_para_xy = pd.get_dummies(df_procesado, \n",
    "                                      columns=columnas_categoricas_originales_para_dummies, \n",
    "                                      prefix=columnas_categoricas_originales_para_dummies, \n",
    "                                      dummy_na=False) # dummy_na=False es generalmente preferido\n",
    "    print(f\"Dimensiones (entrenamiento) después de get_dummies: {df_listo_para_xy.shape}\")\n",
    "\n",
    "    if col_dificultad_situacion in df_listo_para_xy.columns and not df_listo_para_xy[col_dificultad_situacion].isnull().all():\n",
    "        y_objetivo_modelo1 = df_listo_para_xy[col_dificultad_situacion].values\n",
    "    else:\n",
    "        print(f\"ERROR o ADVERTENCIA: La columna objetivo '{col_dificultad_situacion}' no es procesable o está ausente/vacía en df_listo_para_xy.\")\n",
    "        y_objetivo_modelo1 = None \n",
    "\n",
    "    # Redefinimos aquí para asegurarnos que es del scope correcto\n",
    "    columnas_X_finales = [col for col in df_listo_para_xy.columns if col not in columnas_ids_y_etiquetas]\n",
    "    X_features = df_listo_para_xy[columnas_X_finales].values\n",
    "    \n",
    "    print(f\"Matriz 'X_features' (entrenamiento) definida. Shape: {X_features.shape}\")\n",
    "    if y_objetivo_modelo1 is not None:\n",
    "        print(f\"Target 'y_objetivo_modelo1' ({col_dificultad_situacion}) definido. Shape: {y_objetivo_modelo1.shape}\")\n",
    "\n",
    "    # Guardar listas de columnas en GCS usando joblib o pandas.to_pickle\n",
    "    gcs_path_cols_x = f\"gs://{bucket_name}/{prefix_path_artefactos}columnas_X_entrenamiento_final.pkl\"\n",
    "    gcs_path_cols_cat = f\"gs://{bucket_name}/{prefix_path_artefactos}columnas_categoricas_originales.pkl\"\n",
    "\n",
    "    try:\n",
    "        # Usando pandas.to_pickle que funciona bien con rutas gs:// (si gcsfs está instalado)\n",
    "        pd.Series(columnas_X_finales).to_pickle(gcs_path_cols_x)\n",
    "        print(f\"Lista 'columnas_X_finales' guardada en: {gcs_path_cols_x}\")\n",
    "        \n",
    "        pd.Series(columnas_categoricas_originales_para_dummies).to_pickle(gcs_path_cols_cat)\n",
    "        print(f\"Lista 'columnas_categoricas_originales_para_dummies' guardada en: {gcs_path_cols_cat}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error guardando listas de columnas en GCS: {e}\")\n",
    "        print(\"Asegúrate de que fsspec y gcsfs están instalados y que la ruta del bucket es correcta.\")\n",
    "        \n",
    "    print(\"--- Preprocesamiento de Entrenamiento Completado ---\")\n",
    "\n",
    "print(\"\\nCelda 4: Preprocesamiento y guardado de artefactos en GCS completado (o intentado).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dfc4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dividiendo Datos de Entrenamiento ---\n",
      "Error: X_features o y_objetivo_modelo1 no están listos para la división en el script de entrenamiento, o no tienen las mismas dimensiones, o y_objetivo_modelo1 es todo NaN.\n",
      "\n",
      "Celda 5: División de datos completada (o intentada).\n"
     ]
    }
   ],
   "source": [
    "# CELDA 5: División de Datos de Entrenamiento\n",
    "print(\"\\n--- Dividiendo Datos de Entrenamiento ---\")\n",
    "X_train, X_test, y_train, y_test = (np.array([]), np.array([]), np.array([]), np.array([])) # Inicialización\n",
    "\n",
    "# Comprobaciones robustas antes de dividir\n",
    "if X_features is not None and X_features.size > 0 and \\\n",
    "   y_objetivo_modelo1 is not None and y_objetivo_modelo1.size > 0 and \\\n",
    "   X_features.shape[0] == y_objetivo_modelo1.shape[0] and \\\n",
    "   not pd.isna(y_objetivo_modelo1).all():\n",
    "    \n",
    "    # Comprobar si hay suficientes muestras en cada clase para estratificar\n",
    "    unique_classes, counts = np.unique(y_objetivo_modelo1, return_counts=True)\n",
    "    if all(counts >= 2): # O un valor mayor si cv en GridSearchCV es >2 y test_size es pequeño\n",
    "        stratify_param = y_objetivo_modelo1\n",
    "    else:\n",
    "        print(\"Advertencia: No hay suficientes muestras en al menos una clase para estratificar. \"\n",
    "              \"Se procederá sin estratificación. Revisa la distribución de tu variable objetivo.\")\n",
    "        stratify_param = None\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_features, y_objetivo_modelo1, \n",
    "        test_size=0.25, \n",
    "        random_state=42, \n",
    "        stratify=stratify_param # Usar el parámetro de estratificación definido\n",
    "    )\n",
    "    print(f\"Datos de entrenamiento divididos. X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "else:\n",
    "    print(\"Error: X_features o y_objetivo_modelo1 no están listos para la división en el script de entrenamiento, \"\n",
    "          \"o no tienen las mismas dimensiones, o y_objetivo_modelo1 es todo NaN.\")\n",
    "\n",
    "print(\"\\nCelda 5: División de datos completada (o intentada).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c063c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modelo SVM con GridSearchCV para DificultadSituacion (Entrenamiento) ---\n",
      "No se puede proceder con el entrenamiento del modelo, X_train o y_train están vacíos o son inválidos.\n",
      "\n",
      "Celda 6: Entrenamiento del modelo y guardado en GCS completado (o intentado).\n"
     ]
    }
   ],
   "source": [
    "# CELDA 6: Modelo SVM con GridSearchCV para DificultadSituacion (Entrenamiento) (Modificada para GCS)\n",
    "\n",
    "# ------------- POR FAVOR, CONFIGURA ESTAS VARIABLES (si no lo hiciste antes) -------------\n",
    "# bucket_name = \"TU_BUCKET_GCS\" # Ya debería estar definido\n",
    "# prefix_path_artefactos = \"RUTA_PARA_ARTEFACTOS/\" # Ya debería estar definido\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n--- Modelo SVM con GridSearchCV para DificultadSituacion (Entrenamiento) ---\")\n",
    "\n",
    "# Asegurarse de que y_train no esté vacío o todo NaN antes de proceder\n",
    "if X_train.size > 0 and y_train.size > 0 and not pd.isna(y_train).all():\n",
    "    # Definimos GridSearchCV sobre un pipeline SVM\n",
    "    # Usando el kernel polinómico y el param_grid de tu notebook\n",
    "    svm_pipeline_basico = GridSearchCV(\n",
    "        estimator=make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SVC(kernel='poly', random_state=42, probability=True) # probability=True puede ser costoso\n",
    "        ),\n",
    "        param_grid={\n",
    "            'svc__C':       [1e-3, 1e-2, 1e-1, 1, 10, 100, 1e3],\n",
    "            'svc__degree':  [2, 3, 4, 5],\n",
    "            'svc__gamma':   ['scale', 'auto'],\n",
    "            'svc__coef0':   [0.0, 0.1, 1.0, 10.0]\n",
    "        },\n",
    "        scoring='accuracy',\n",
    "        cv=5, # StratifiedKFold se usa por defecto si el estimador es un clasificador y y es binario/multiclase\n",
    "        n_jobs=-1, # Usar todos los procesadores disponibles\n",
    "        verbose=2\n",
    "    )\n",
    "    print(f\"Pipeline SVM + GridSearchCV definido.\")\n",
    "\n",
    "    print(\"\\nEntrenando svm_pipeline_basico (GridSearchCV)...\")\n",
    "    try:\n",
    "        svm_pipeline_basico.fit(X_train, y_train)\n",
    "        print(\"✅ GridSearchCV completado.\")\n",
    "        print(\"Mejores parámetros encontrados:\", svm_pipeline_basico.best_params_)\n",
    "        print(\"Mejor puntuación (accuracy) en CV:\", svm_pipeline_basico.best_score_)\n",
    "\n",
    "        # Usar el mejor estimador encontrado por GridSearchCV para predicciones\n",
    "        best_svm_model = svm_pipeline_basico.best_estimator_\n",
    "\n",
    "        print(\"\\nEvaluando en conjunto de prueba (entrenamiento)...\")\n",
    "        y_pred_test = best_svm_model.predict(X_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        print(f\"Accuracy en el conjunto de prueba: {accuracy_test:.4f}\")\n",
    "        \n",
    "        # dificultad_map ya está definido globalmente en Celda 4\n",
    "        dificultad_map_inverso = {v: k for k, v in dificultad_map.items()}\n",
    "        \n",
    "        # Asegurarse que y_test no esté vacío y clases_unicas_ordenadas se pueda generar\n",
    "        if y_test.size > 0 and not pd.isna(y_test).all():\n",
    "            # Para target_names, usamos y_test para reflejar las clases presentes en el conjunto de prueba\n",
    "            # o y_objetivo_modelo1 para todas las clases originales\n",
    "            clases_originales = sorted([key for key in dificultad_map.values()]) # 0, 1, 2\n",
    "            clases_presentes_y_test = sorted(np.unique(y_test[~pd.isna(y_test)]).astype(int))\n",
    "\n",
    "            # Usar las clases originales para el reporte para consistencia, si y_test no las tiene todas, se marcarán con 0.\n",
    "            target_names_report = [dificultad_map_inverso.get(i, str(i)) for i in clases_originales]\n",
    "            \n",
    "            print(\"\\nReporte de Clasificación (Conjunto de Prueba del Entrenamiento):\")\n",
    "            print(classification_report(y_test, y_pred_test, target_names=target_names_report, labels=clases_originales, zero_division=0))\n",
    "\n",
    "            cm = confusion_matrix(y_test, y_pred_test, labels=clases_originales)\n",
    "            plt.figure(figsize=(6,4))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                        xticklabels=target_names_report, yticklabels=target_names_report)\n",
    "            plt.xlabel('Predicción')\n",
    "            plt.ylabel('Real')\n",
    "            plt.title('Matriz de Confusión - SVM (GridSearchCV) (Entrenamiento)')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No se pudo generar el reporte de clasificación (y_test vacío o con NaNs).\")\n",
    "\n",
    "        # Guardar el MEJOR modelo entrenado (el pipeline completo con el mejor estimador) en GCS\n",
    "        nombre_modelo_gcs = f\"gs://{bucket_name}/{prefix_path_artefactos}modelo_svm_gs_entrenado.joblib\"\n",
    "        try:\n",
    "            with fsspec.open(nombre_modelo_gcs, 'wb') as f:\n",
    "                 joblib.dump(best_svm_model, f)\n",
    "            print(f\"\\nMejor modelo (GridSearchCV) entrenado guardado en: {nombre_modelo_gcs}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el modelo en GCS: {e}\")\n",
    "            print(\"Asegúrate de que fsspec y gcsfs están instalados y que la ruta del bucket es correcta.\")\n",
    "            \n",
    "    except ValueError as ve:\n",
    "        print(f\"Error durante GridSearchCV o el entrenamiento: {ve}\")\n",
    "        print(\"Esto puede ocurrir si 'cv' es mayor que el número de muestras en la clase más pequeña \"\n",
    "              \"durante la estratificación, o si y_train tiene un formato inesperado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Un error inesperado ocurrió durante el entrenamiento o evaluación: {e}\")\n",
    "else:\n",
    "    print(\"No se puede proceder con el entrenamiento del modelo, X_train o y_train están vacíos o son inválidos.\")\n",
    "\n",
    "print(\"\\nCelda 6: Entrenamiento del modelo y guardado en GCS completado (o intentado).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
